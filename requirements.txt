--extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu126

# common
click
faker
pandas
psycopg2-binary
openpyxl
python-pptx
python-dotenv

# streamlit
streamlit
streamlit-tree-select

# crewai
crewai
crewai_tools

# langgraph + langchain
langgraph
langchain_core
langchain-community
langchain_experimental
langchain-ollama                # install: curl -fsSL https://ollama.com/install.sh | sh
langchain_nvidia_ai_endpoints   # api key: https://build.nvidia.com/meta/llama-3_1-405b-instruct
langchain_huggingface

# llama-index
llama-index
llama-index-llms-ollama
llama-index-embeddings-ollama
llama-index-llms-huggingface
llama-index-llms-huggingface-api
llama-index-embeddings-huggingface
llama-index-llms-langchain
spacy
llama-index-finetuning
llama-index-embeddings-langchain

# Yandex GPT
yandex-cloud-ml-sdk
llama-index-embeddings-yandexgpt

# Unsloth
unsloth
xformers 
trl
peft
accelerate
bitsandbytes

# Llama.cpp
ggify @ git+https://github.com/akx/ggify
# CMAKE_ARGS="-DGGML_BLAS=on -DGGML_BLAS_VENDOR=OpenBLAS -DGGML_CUDA=on" must be set, e.g.
# > CMAKE_ARGS="-DGGML_BLAS=on -DGGML_BLAS_VENDOR=OpenBLAS -DGGML_CUDA=on" pip install 'llama-cpp-python==0.2.55'
llama-cpp-python
